{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the required Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_name=\"scikit:1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dockerfile = \"\"\"\n",
    "FROM python:3.6-jessie\n",
    "\n",
    "RUN pip install flask opencv-python pandas numpy scipy scikit-learn\n",
    "\n",
    "RUN find / -name \"*.pyc\" -exec rm -f {} \\;\n",
    "\n",
    "RUN mkdir -p /opt/program\n",
    "RUN mkdir -p /opt/ml/model\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PATH=\"/opt/program:${PATH}\"\n",
    "\n",
    "COPY app.py /opt/program\n",
    "WORKDIR /opt/program\n",
    "\n",
    "EXPOSE 8080\n",
    "ENTRYPOINT [\"python\", \"app.py\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app = \"\"\"\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import model\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/ping')\n",
    "def ping():\n",
    "    return (\"\", 200)\n",
    "\n",
    "@app.route('/invocations', methods=[\"POST\"])\n",
    "def invoke():\n",
    "    # load image from POST and convert it to opencv\n",
    "    data = request.stream.read()\n",
    "    \n",
    "    payload = json.loads(data)\n",
    "    print(payload, model)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\", \"test\"] ):\n",
    "       raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "\n",
    "    train = sys.argv[1] == \"train\"\n",
    "    test = sys.argv[1] == \"test\"\n",
    "    \n",
    "    if train:\n",
    "       model.train()\n",
    "\n",
    "    elif test:\n",
    "       model.test(sys.argv[2:])\n",
    "       \n",
    "    else:\n",
    "       model.serve()\n",
    "\n",
    "       app.run(port=8080, host=\"0.0.0.0\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('app.py', 'w') as f:\n",
    "    f.write(app)\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo docker build -f Dockerfile -t $tag_name ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the program module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = os.path.join(prefix, 'input/data')\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "model_filename = os.path.join(model_path, 'model.pkl')\n",
    "\n",
    "def train():\n",
    "    print(\"Training mode\")\n",
    "    \n",
    "    try:\n",
    "        # This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "        # File mode, the input files are copied to the directory specified here.\n",
    "        channel_name='training'\n",
    "        training_path = os.path.join(input_path, channel_name)\n",
    "\n",
    "        # Read in any hyperparameters that the user passed with the training job\n",
    "        with open(param_path, 'r') as tc:\n",
    "            hyperparameters = json.load(tc)\n",
    "\n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError(('There are no files in {}.\\\\n' +\n",
    "                              'This usually indicates that the channel ({}) was incorrectly specified,\\\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        raw_data = [ pd.read_csv(file, sep=',', header=None ) for file in input_files ]\n",
    "        train_data = pd.concat(raw_data)\n",
    "        \n",
    "        # labels are in the first column\n",
    "        Y = train_data.ix[:,0]\n",
    "        X = train_data.ix[:,1:]\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "\n",
    "        #if hyperparameters['algorithm'] == 'logistic':\n",
    "        #elif hyperparameters['algorithm'] == 'random_forest':\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        joblib.dump(model, open(model_filename, 'wb'))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\\\n' + trc)\n",
    "            \n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\\\n' + trc, file=sys.stderr)\n",
    "        \n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "def serve():\n",
    "    print(\"Predicting mode\")\n",
    "\n",
    "    model = joblib.load(open(model_filename, 'rb'))\n",
    "    X = np.random.rand(1,10)\n",
    "    print( model.predict( X ))\n",
    "    return\n",
    "\n",
    "def test(payload):\n",
    "    X = eval(payload[0])\n",
    "    model = joblib.load(open(model_filename, 'rb'))\n",
    "    print( model.predict( [X] ))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = \"\"\"\n",
    "{\n",
    "  \"epochs\": 10,\n",
    "  \"learning_rate\": 0.1\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p input/config\n",
    "!mkdir -p program\n",
    "\n",
    "with open('program/model.py', 'w') as f:\n",
    "    f.write(model)\n",
    "    f.flush()\n",
    "    f.close()\n",
    "    \n",
    "with open('input/config/hyperparameters.json', 'w') as f:\n",
    "    f.write(hyperparameters)\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p input/data/training\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "pd = pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names)\n",
    "pd.to_csv('input/data/training/iris.csv', header=None, index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker run --rm --name 'my_model' \\\n",
    "    -v \"${PWD}/model:/opt/ml/model\" \\\n",
    "    -v \"${PWD}/input:/opt/ml/input\" \\\n",
    "    -v \"${PWD}/program/model.py:/opt/program/model.py\" scikit:1.0 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker run --rm --name 'my_model' \\\n",
    "    -v \"${PWD}/model:/opt/ml/model\" \\\n",
    "    -v \"${PWD}/input:/opt/ml/input\" \\\n",
    "    -v \"${PWD}/program/model.py:/opt/program/model.py\" scikit:1.0 test \"[4.6, 3.1, 1.5, 0.2]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now it's time to push everything to the correct repo\n",
    "Go to the terminal and do the job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
